% This is the first main part of the thesis.
% Here the approach you and your supervisor decided on should be explained.
% Usually, first on a higher level and then in detail including implementation details.
% So the question that is answered is: How do you try to solve the problem at hand?

\chapter{Concept and Implementation}
\label{chap:concept_and_implementation}

Now for the actual implementation:\\
We will first consider the general control flow of our application, both for the bare-metal and OS based version.
For the Linux version specifically we will then compare multiple approaches to optimize the OS both in terms of average performance as well as worst case latencies.
These different versions will later be compared to the bare-metal version in the \nameref{chap:experiments} chapter.
The bare-metal version demands a more detailed look, as it is the focus of this thesis.
For the bare-metal version we will first look at the bootup process on the Raspberry Pi and how to produce a Rust binary that successfully boots.
From that we will continue with how the bindings to Circle were created as well as how and why an abstraction on top of it was written to make the underlying C code adhere to Rusts safety guarantees.

\section{The Control Loop}
\label{sec:concept_and_implementation:control_flow}

The general control flow follows the principle of a super loop.
On startup we initialize the communication hardware and from there on it's just a fetch, compute, update loop.
In the fetch step we get the current position of the actuator as well as the control value and the time passed since the last cycle.
The position is fetched through SPI from the IC-MU and the duration since the last cycle from a CPU timer.
For increased reproducability we will mock an external control value input by replacing it with a fixed signal based on timers on the Raspberry Pi.
In the compute step we apply those values to our PID-controller formula in order to get the new output value.
Last, in the update step, we update the duty cycle of the output PWM signal based on the just computed output value.

\section{Linux based version}
\label{sec:concept_and_implementation:linux}

Interacting with the SPI and PWM hardware on linux works through the spidev character device in /dev/spidev0.0 and the pwm interface in /sys/class/pwm .
For Rust there exists a library called rppal that provides a simple interface for interacting with these.
Because of this, it will be used for the linux versions.

\subsection{Approaches to minimize jitter}
\label{sec:concept_and_implementation:linux:approaches}

In order to give the linux version the best chance to compete with the bare-metal version we try two optimization approaches.
First, we tell the linux scheduler to reserve an entire core for our program, so that it is never moved between cores and never interrupted by core local interrupts.
By this we aim to improve the worst case iteration times without changing the average case.
In an attempt to go even further we will also try a linux kernel with the PREEMPT\_RT patchset,
which replaces the scheduler by a realtime capable one and makes every section of the kernel preemptible.
The idea behind this is that even the parts of our program that run in kernel space,
by making syscalls to the spi and pwm kernel drivers, run at a higher priority than other kernel tasks.
To verify if our approaches made any significant difference we will also be running an unmodified stock kernel with our program at default priority.

\subsection{Setup with rppal}
\label{sec:concept_and_implementation:linux:rppal}

Setting up Spi and PWM through rppal isn't very complex,
but it comes with a few small caveats that are noteworthy
and is a good primer on how linking to external code works in Rust which will be useful when we turn to the bare-metal version.

Rust projects are built using the Cargo build system. This allows us to add rppal into the compilation process by editing our projects Cargo.toml file.

\begin{verbatim}
[package]
name = "os-based"
version = "0.1.0"
edition = "2021"

[dependencies]
ctrlc = "3.4.4"
embedded-hal = "1.0.0"
pid-ctrl = "0.1.4"
rppal = { version = "0.18.0", features = ["hal"] }

[profile.release]
lto = true
\end{verbatim}

This pulls the rppal source code from crates.io and builds it together with our program and links the two afterwards.
Alternatively we could have specified a link or path to a custom version of rppal if that were needed.
Setting up the devices is then done by including the relevant types and creating instances of them.

\begin{lstlisting}[language=Rust,style=colouredRust]
use rppal::{spi::Spi, pwm::Pwm};
Spi::new(Bus::Spi0, SlaveSelect::Ss0, 20_000_000, Mode::Mode0).unwrap();
Pwm::with_frequency(Channel::Pwm0, 1_000., 0.5, Polarity::Normal, false).unwrap();
\end{lstlisting}

On a stock Raspberry Pi 4 with Raspberry Pi OS this would still fail, because by default the spi and pwm device tree overlays are not enabled.
In order to enable them we need to set dtparam=spi=on in /boot/firmware/config.txt for spi and dtoverlay=pwm for pwm.

\subsection{Getting the current position}

In \nameref{sec:background:hardware:spi} and \nameref{sec:background:hardware:ic-mu} we have already seen how SPI and the position encoder that we are using work.
This leaves us with how to transmit the actual position data.
The position transmission is initiated by the SPI master by sending the SDAD\_TRANSMISSION opcode.
The IC-MU chip answers by echoing the opcode and appending the position.
The format and length of the position is dependent on several configuration values on the IC-MU, but for our purposes the default configuration is appropriate.
In the default configuration this is 19 bits of actual position data with five zeros added as padding.
In Rust the transmission looks like this:

\begin{lstlisting}[language=Rust,style=colouredRust]
const SDAD_TRANSMISSION: u8 = 0xa6;
let mut buf = [SDAD_TRANSMISSION, 0, 0, 0, 0];

spi.transfer_in_place(&mut buf).unwrap();
let position = u32::from_be_bytes(buf[1..].try_into().unwrap()) >> 13;
\end{lstlisting}

Here we transmit by writing in the same buffer that we are reading from for sending, which means we need four bytes of space, one for the opcode and 3 for the data.
To make converting to an integer easier we add a fifth byte, so we can just interpret the last 32 bits of the buffer as our position.
Because the IC-MU sends in big endian we use u32::from\_be\_bytes() for the conversion.

\subsection{Providing a PID controller}

While is the aim of this thesis to enable flexible implementation of different control schemes, implementing these is not in our scope.
For now, we will implement a simple PID controller that stays the same between the linux and bare-metal versions.

For this we decided on the pid-ctrl library to be used, as it is easy to use, works on bare-metal and supports differing time deltas.

The process of including it is analogous to rppal. In fact in the \nameref{sec:concept_and_implementation:linux:rppal} chapter, we already included it in our build process.
So all that is to do is to use it in our code.

\begin{lstlisting}[language=Rust,style=colouredRust]
let mut pid = PidCtrl::new_with_pid(10., 1., 5.);

loop {
    ...
    let position = get_position(spi);
    pid.setpoint = get_setpoint();
    let output = pid
        .step(pid_ctrl::PidIn::new(position, iteration_time.as_secs_f64()))
        .out;
    ...
}
\end{lstlisting}

\section{Bare-Metal}
\label{sec:concept_and_implementation:bare_metal}

Bare metal programming is traditionally something reserved for microcontrollers or os kernels.
While the Raspberry Pi 4 very much isn't a microcontroller but a fully fledged PC capable of running desktop class operating systems,
its simple boot process and access to low level IO such as $I^2C$, SPI and GPIO pins capable of analog input and output still allow it as if it were a microcontroller.

\subsection{HAL vs Circle}
\label{sec:concept_and_implementation:bare-metal:hal}

As we have seen in \nameref{sec:background:rust:embedded} the traditional way to program for a microcontroller in Rust
is to create a library for it that implements all the traits from the embedded-hal crate and a second library for the bootup process.
Doing that from scratch is as significant task that would exceed the scope of a bachelorthesis by quite a bit.
But in order to enable a better evaluation of Rust's suitability for embedded systems we will demonstrate how such an implementation would look for the Gpio pins in \nameref{sec:concept_and_implementation:hal}.
For the actually functional bare-metal program we will be using a different route.
The Circle library is a C++ framework that provides bare-metal access to pretty much all of the Rpi's available hardware.
That means not only Gpio, Spi and I2c, but also the more complex subsystems, such as PCIe, USB, display outputs and ethernet.
So we are going to use this library through Rust's Foreign Functions Interface (FFI from now on).

\subsection{Cross compiling for bare-metal aarch64}
\label{sec:concept_and_implementation:bare-metal:cross}

On linux there are two main ways of obtaining a Rust compiler.
Through your distributions package manager or through rustup,
a tool for managing if neccessary multiple versions of rustc, as well as any connected tooling.
For cross compilers the first option is nearly nonexistent, so we need to use rustup.
Rustup is easily installed on linux by running the following command.
\begin{verbatim}
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
\end{verbatim}
To be able to cross compile to aarch64-unknown-none we run
\begin{verbatim}
rustup target add aarch64-unknown-none
\end{verbatim}
For most targets the rustup target add command does two things.
First it downloads the compiler backend for the new target architecture.
Second it downloads a precompiled version of the rust standard library for the new target if available.
Since we are adding a bare-metal target there is no complete standard library, but Rust's standard library is split into three parts of which we can use two.
The lowest and most constraint part is the core library.
It contains primitive types and operations on them.
Because this part is built purely on llvm primitives it is available for every target and does not need to be compiled as it lives inside the compiler.
The second part available to bare-metal systems is the alloc library, this adds types,
operations and traits that depend on the existence of a memory allocator.
If we want to use this part we need to provide a memory allocator.
Fortunately for us Circle provides a malloc and free implementation, which we can use as our allocator.
The third part of the standard library is called std and contains all types that rely on syscalls to the underlying operationg system.
This means networking, file system access and timing.

If we are only cross compiling rust code this would already be enough.
But since we also want to compile Circle and then link the final binaries together we need a C cross compiler as well as a linker.
Arm provides precompiled toolchains for C so we will use the latest one provided by them at the time of writing.
%https://developer.arm.com/downloads/-/arm-gnu-toolchain-downloads

There is one final thing to do, when linking to external binaries Rust uses \$\{target\}-gcc as the linker, so in our case aarch64-unknown-none-gcc.
To use aarch64-none-elf-ld instead which we got from Arm in our project directory we add a .cargo/config.toml file with the following content:
\begin{verbatim}
[target.aarch64-unknown-none]
linker = "aarch64-none-elf-ld"

[build]
target = "aarch64-unknown-none"
\end{verbatim}
The linker line sets the linker to the correct binary and the target lines changes the default target when using cargo.

\subsection{Bootup process of the Raspberry Pi 4}
\label{sec:concept_and_implementation:bare-metal:boot}

The first part of creating a bare-metal controller is creating a binary that even boots on the Raspberry Pi.
\begin{enumerate}
    \item The on-chip first stage bootloader is loaded from address 0x60000000
    \item It checks if a recovery.bin is present on the first FAT32 partition of the SD-card. If it is found it is flashed to the onboard EEPROM chip and the Rpi is rebooted.
    \item Else it loads the second stage bootloader and its configuration from the EEPROM
    \item The second stage bootloader loads the third stage bootloader either from the SD-card, a USB storage device or the network, depending on the configuration.
          The third stage bootloader is split into the binary start4.elf, the relocation table fixup4.dat and config.txt for the configuration.
    \item The third stage bootloader loads the kernel image and jumps to address 0x80000. By default this is kernel8.img, but the kernel file name can be set in config.txt.
    \item In some cases this kernel.img may be another bootloader such as u-boot, which could then load grub.
          This additional boot part is used in many linux distributions, that support uefi boot on aarch64 and not the Raspberry Pi specific chain.
\end{enumerate}

To produce a bootable rust binary we start from a clean project folder generated with cargo new.
This clean project contains a Cargo.toml for the build system configuration and a src/main.rs with the actual code.

First we will add a .cargo/config.toml similar to what we saw in \nameref{sec:concept_and_implementation:bare-metal:cross}.
\begin{verbatim}
[target.aarch64-unknown-none]
linker = "aarch64-none-elf-ld"
rustflags = ["-C", "link-arg=Tlink.ld"]
    
[build]
target = "aarch64-unknown-none"
\end{verbatim}
The added rustflags line allows us to control which logical addressess code is placed at in the linking step.
To control this we create link.ld:
\begin{verbatim}
SECTIONS
{
    . = 0x80000;
    .text :
    {
        *(.text._start)
        *(.text*)
    }
}
\end{verbatim}
The .text section of a binary is where the actual instructions lie as opposed to .data and .bss.
What we are doing here is keeping all of the segments in .text, placing .text.\_start at the beginning of .text and let .text begin at 0x80000.
As we already discussed 0x80000 is the address to which the Raspberry Pi jumps after loading the kernel.
Now for the actual Rust code. Since there is not standard library on bare-metal we need to tell Rust not to link to the standard library.
This is done by prepending \#\![no\_std] to main.rs.
The second thing to prepend is \#\![no\_main] because otherwise Rust expects a main function that can be called with the runtime setup required for command line arguments.
On bare-metal we neither have command line arguments nor a runtime.
One thing that the standard library used to provide for us was a panic\_handler implementation.
As the name suggests, the panic handler controls panic exceptions.
On an operating system that typically includes logging the error message to stderr, but for bare-metal Rust expects us to provide an implementation.
That leaves on final task, writing the function that will actually be run and ensuring that it is linked to the .text.\_start section.
\begin{lstlisting}[language=Rust,style=colouredRust]
#![no_std]
#![no_main]

use core::panic::PanicInfo;

#[panic_handler]
fn panic(_: &PanicInfo) -> ! {
    loop {}
}

#[no_mangle]
#[link_section = ".text._start"]
pub extern "C" fn _start() -> ! {
	loop {}
}
\end{lstlisting}

The no\_mangle attribute before the start function tells the Rust compiler not to mangle the function name, which by default it would do.
The link\_section attribute ensures that our start function is linked to the section we forced in the linker script to be included at address 0x80000.
The pub attribute makes the function visible to the linker instead of only to the compiler.
The extern C attribute tells the compiler to adhere to the C ABI for the start function.
This is necessary because the Rust ABI is unstable and may be more complicated than jumping to the start address.

At this point we can obtain a binary by running cargo build.
But this binary would be an elf executable that cannot be executed without a program loader.
ELF in this context stands for executable-linkable-format and is the file format that linux expects for executable binaries,
with a header that contains all the relevant information for the dynamic linker.
The bootloader however just copies the kernel image to RAM and sets the instruction pointer to 0x80000.
This means that we have to rip out the code from our elf binary and create a flat binary without an elf header.
The program that does this is called objcopy and is a standard part of the gnu toolchain.
This means that we already have the correct version aarch64-none-elf-objcopy available from installing the C cross compiler.

\begin{verbatim}
cargo build --release
aarch64-none-elf-objcopy -O binary \
    target/aarch64-unknown-none/release/<project-name> \
    kernel8.img
\end{verbatim}

When building Rust only bare-metal project there is an easier way to obtain objcopy than to install the complete Gnu toolchain.
\begin{verbatim}
rustup component add llvm-tools
cargo install cargo-binutils
\end{verbatim}
Which allows to build and extract the binary in one command with any target available that was added through rustup.
\begin{verbatim}
cargo objcopy --release -- -O binary kernel8.img
\end{verbatim}

\subsection{Compiling circle and linking it to Rust}
\label{sec:concept_and_implementation:bare-metal:ffi}

Many languages provide a way to link to C ABI (Application Binary Interface) functions, examples for this are C++ with its extern C, Haskell with its FFI module as well as Python.
The reasons for this are very simple, for one, the C ABI for each target platform is stable and allows thus to be used as a common language to bridge other languages.
Second, C is still a widely used language with many useful libraries in any field of programming, which can then be used by languages with a C interface.

As Rust is a systems programming language the prevalence of C libraries in areas interesting to Rust is even greater.
In its most basic form the Rust FFI system works through declaring functions as extern C, when calling Rust functions from C
and declaring extern C functions in Rust without a definition, when calling C code from Rust.

\begin{lstlisting}[language=Rust,style=colouredRust]
use std::ffi::c_int;

extern "C" {
    fn c_function(number1: c_int) -> c_int;
}

#[no_mangle]
pub extern "C" fn rust_function(number2: c_int) -> c_int {
    number2
}

fn calling_c_from_rust() {
    let _ = unsafe { c_function(42) };
}
\end{lstlisting}

\begin{lstlisting}[language=C]
int rust_function(int number2);

int c_function(int number1) {
    return number1;
}

void calling_rust_from_c(void) {
    rust_function(42);
}
\end{lstlisting}

Writing these bindings manually is fine for a handful of functions, but for anything larger in scope some automation would be useful.
Fortunately there are a few well supported libraries which aim to automate this under different circumstances.
Bindgen takes in C header files and generates a Rust file with the appropriate extern C declarations from it.
It works both as a executable for manual use as well as a library that can be integrated into the build process.
Since intercompatibility with C code has been important for Rust from the beginning,
bindgen is an official project maintained under the same umbrella as the compiler and cargo.
One company that makes heavy use of Rust is Mozilla for their firefox browser.
Because firefox is mostly written in C the opposite case of bindgen, calling Rust from C code is very common in the firefox codebase.
As a result Mozilla created cbindgen, which takes in Rust files and creates a C header with declarations for all public functions.
For interacting with C++ code there are two more libraries, cxx and autocxx.
Because C++ functions do not neccessarily adhere to the C ABI calling them from Rust and vice versa can be difficult with bindgen, as we will see later.
Instead cxx takes a declaration for a common interface between C++ and Rust and generates a bridge from pure C functions that both languages can access.
Autocxx by Google is similar to bindgen for C++, but instead of generating a Rust interface directly it generates a cxx interface, which in turn generates the Rust interface.

To come back to our original problem, which one of these should we use to access the circle library from our Rust code?
Since circle is written in C++ and we just want to call C++ functions from Rust, not the other way around, autocxx would be the ideal choice.
Unfortunately at the time of writing autocxx does not work with bare-metal programs.
There is ongoing work on this and autocxx itself can actually be compiled for bare-metal, but one of its dependencies can't.
This leaves us with two options, use cxx and manually write the interface, or use bindgen and work with a more convoluted interface.
Since bindgen has been stable for a long time and cxx is still partially a work in progress wo chose to use bindgen for a more meaningful insight into Rust.

As mentioned earlier bindgen can be used either as a command line utility to generate the bindings once,
or as a build dependency to automatically generate the bindings at compile time.
We are going to use the second approach.
To add bindgen as a build dependency we add
\begin{verbatim}
[build-dependencies]
bindgen = "0.69.4"
\end{verbatim}
to our Cargo.toml.

Cargo provides the option of creating a build.rs file, which will be compiled and executed before the actual compile.
In order to create the bindings and link the final binaries correctly we create a build.rs.
\begin{lstlisting}[language=Rust,style=colouredRust]
use bindgen::{Builder, MacroTypeVariation};
use std::{env, path::PathBuf};
    
fn main() {
    ...
}    
\end{lstlisting}

Inside the main function we do three different things.
First, setting up the linker search path, second, linking to the correct binaries and third generating the bindings for Rust.
For all this we have placed the circle source code in the circle directory in our project folder as well as configured and built the circle library.
We will take a more detailed look at configuring and compiling circle soon, but for now the focus is on the build script.

The linker search path is expanded like this:
\begin{lstlisting}[language=Rust,style=colouredRust]
let manifest_dir = PathBuf::from(env::var("CARGO_MANIFEST_DIR").unwrap());
println!(
    "cargo:rustc-link-search={}",
    manifest_dir.join("circle").display()
); // for circle.ld
println!(
    "cargo:rustc-link-search={}",
    manifest_dir.join("circle/lib/usb").display()
); // for libusb.a
println!(
    "cargo:rustc-link-search={}",
    manifest_dir.join("circle/lib/input").display()
); // for libinput.a
println!(
    "cargo:rustc-link-search={}",
    manifest_dir.join("circle/lib/fs/fat").display()
); // for libfatfs.a
println!(
    "cargo:rustc-link-search={}",
    manifest_dir.join("circle/lib/fs").display()
); // for libfs.a
println!(
    "cargo:rustc-link-search={}",
    manifest_dir.join("circle/lib").display()
); // for libcircle.a
\end{lstlisting}

Then we link to the binaries mentioned in the above code:
\begin{lstlisting}[language=Rust,style=colouredRust]
println!("cargo:rustc-link-lib=usb");
println!("cargo:rustc-link-lib=input");
println!("cargo:rustc-link-lib=fatfs");
println!("cargo:rustc-link-lib=fs");
println!("cargo:rustc-link-lib=circle");
\end{lstlisting}

Generating the bindings is simple thanks to bindgen, we generate bindings for all symbols in wrapper.hpp,
a file that we will write where we include all the headers interesting to us.
Notable are the use\_core() and vtable\_generation(true) methods.
Use\_core() tells bindgen to use only types from the core library instead of std in the bindings, which is necessary for us as we are targeting a bare-metal environment.
Vtable\_generation(true) enables generating types for the vtables of C++ classes.
This allows us to make calls to inherited functions of classes.
\begin{lstlisting}[language=Rust,style=colouredRust]
let bindings = Builder::default()
    .header("wrapper.hpp")
    .use_core()
    .clang_arg(format!(
        "-I{}",
        manifest_dir.join("circle/include").display()
    ))
    .vtable_generation(true)
    .default_macro_constant_type(MacroTypeVariation::Signed)
    .parse_callbacks(Box::new(bindgen::CargoCallbacks::new()))
    .generate()
    .expect("Unable to generate bindings");

let out_path = PathBuf::from(env::var("OUT_DIR").unwrap());
bindings
    .write_to_file(out_path.join("bindings.rs"))
    .expect("Couldn't write bindings!");
\end{lstlisting}

The build script places the generated bindings in a file called bindings.rs in the cargo build directory.
To include this file in our main Rust code we create a new source file that includes the bindings:
\begin{lstlisting}[language=Rust,style=colouredRust]
#![allow(non_upper_case_globals)]
#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(improper_ctypes)]
#![allow(unused)]

include!(concat!(env!("OUT_DIR"), "/bindings.rs"));
\end{lstlisting}
Because the bindings will use the C++ type and function names we would get a lot of warnings for not following Rust naming conventions.
To ignore the warnings we add some allow directives to the file.

Compiling and configuring Circle works like this:
Obtain the source code for Circle either from a tarball or the repository, we used the Step46 tag as it was the latest at the time of writing.
Inside of the circle source directory execute the following commands:
\begin{verbatim}
./configure --raspberrypi 4 --prefix aarch64-none-elf-
./makeall
\end{verbatim}

To create a bootable binary from this we need to create a suitable main.rs and .cargo/config.toml.
Both are very similar to what we already saw in the \nameref{sec:concept_and_implementation:bare-metal:boot} chapter, so we will show only the differences here.
In the .cargo/config.toml we only change the compile flags to use Circle's linker script and .init section as the boot function.
Circle's linker script is not as simplistic as ours was, because it provides the necessary sections for static variables, constants and a heap.
The .init section is defined in the main circle library and provides a bootup function that initializes the .bss and .data sections correctly by zeroing them and copying any constants to RAM.
\begin{verbatim}
...
rustflags = ["-C", "link-args=--section-start=.init=0x80000 -Tcircle.ld"]
...
\end{verbatim}

In the main.rs instead of the \_start function we create a function called main with the type void $\rightarrow$ int,
because Circle links to such a function in order to call it after the bootup initilization is done.
\begin{lstlisting}[language=Rust,style=colouredRust]
...
#[no_mangle]
pub unsafe extern "C" fn main() -> c_int {
    ffi::reboot()
}
...
\end{lstlisting}

Building the final binary works the same as in \nameref{sec:concept_and_implementation:bare-metal:boot}.
This leaves only one final step to make the Raspberry Pi boot our Rust binary.
As mentioned int the Rpi boot process we need the start4.elf, fixup4.dat, bcm2711-rpi-4-b.dtb and config.txt files on the final SD card or USB stick.
These can be obtained from the official Raspberry Pi repository, but circle can download them for us.
To download them through circle call make in the circle/boot directory.

\subsection{The final implementation}

\section{Rust native HAL}
\label{sec:concept_and_implementation:hal}

Instead of using an foreign language library like Circle for this project we could also have written our own Rust native HAL.
This would provide several key benefits:
\begin{itemize}
    \item Vastly simpler build process, completely eliminating the need for the C toolchain
    \item Upholding Rusts memory safety guarantees, which we largely lost/ignored when using Circle
    \item Possibly higher performance because we could use link time optimization on the entire program
    \item Access to any Rust crate that depends on an embedded-hal implementation.
\end{itemize}

In order to understand why we chose against this approach let us look at the complexity it already takes to implement a HAL just for the GPIO pins of the Raspberry Pi.
A pure native Rust stack for the Raspberry Pi 4 would consist out of the following components:
\begin{enumerate}
    \item A Peripheral Access Crate (PAC) that contains all the memory addresses for the memory mapped IO. This can be generated using svd2rust from an svd file.
    \item A HAL crate that implements the embedded-hal traits, embedded-io traits for uart, dma, pcie and a critical section implementation for the bcm2711 processor.
    \item A Board Support Crate/Package (BSP) that contains board but not processor specific implementations, such as the boot process, usb and ethernet.
\end{enumerate}

Forunately Broadcom provides the svd files for their processors and someone already has generated a PAC from them and published it on crates.io.
From the HAL we implemented the GPIO pins as well as single core critical sections and from the BSP we implemented an entry macro to mark the boot function and a linker script that supports the .data and .bss sections.

For the HAL gpio implementation we need to take the GPIO struct from the PAC that contains all addresses of the IO registers and use it to create a new pin type that implements the embedded-hal traits.
GPIO pins on the Raspberry Pi can be in input, output and alternate function mode. These modes can be switched through the fsel (function select) registers.
In C one would have to check at runtime if a pin is in the correct mode before using it.
By modelling the modes as type parameters in Rust we can check at compile time that functions only use pins in the correct mode, with obvious benefits for performance and binary size.

\begin{lstlisting}[language=Rust,style=colouredRust]
use core::marker::PhantomData;

pub trait GpioExt {
    type Parts;

    fn split(self) -> Self::Parts;
}

pub struct Unknown;

pub struct Input<MODE> {
    _mode: PhantomData<MODE>,
}

pub struct Floating;
pub struct PullDown;
pub struct PullUp;

pub struct Output;

use bcm2711_lpa::GPIO;
use embedded_hal as hal;
use core::convert::Infallible;

pub struct Parts {
    pub pin0: Pin0<Unknown>,
}

impl GpioExt for GPIO {
    type Parts = Parts;

    fn split(self) -> Parts {
        Parts {
            pin0: Pin0 { _mode: PhantomData },
        }
    }
}

pub struct Pin0<MODE> {
    _mode: PhantomData<MODE>,
}
\end{lstlisting}

The Pin0 type can be now differentiated into Pin0<Output>, Pin0<Unknown>, Pin0<Input<Floating>>, Pin0<Input<PullDown>> and Pin0<Input<PullUp>>.
For these types we can now implement constructors to switch between the types:

\begin{lstlisting}[language=Rust,style=colouredRust]
impl<MODE> Pin0<MODE> {
    pub fn into_input(self) -> Pin0<Input<Floating>> {
        unsafe { (*GPIO::PTR).gpio_pup_pdn_cntrl_reg0().set_bits(|w| {w.gpio_pup_pdn_cntrl0().none()})}

        unsafe { (*GPIO::PTR).gpfsel0().set_bits(|w| {w.fsel0().input()}) };

        Pin0 { _mode: PhantomData }
    }

    pub fn into_input_pulldown(self) -> Pin0<Input<PullDown>> {
        unsafe { (*GPIO::PTR).gpio_pup_pdn_cntrl_reg0().set_bits(|w| {w.gpio_pup_pdn_cntrl0().down()})}

        unsafe { (*GPIO::PTR).gpfsel0().set_bits(|w| {w.fsel0().input()}) };

        Pin0 { _mode: PhantomData }
    }

    pub fn into_input_pullup(self) -> Pin0<Input<PullUp>> {
        unsafe { (*GPIO::PTR).gpio_pup_pdn_cntrl_reg0().set_bits(|w| {w.gpio_pup_pdn_cntrl0().up()})}

        unsafe { (*GPIO::PTR).gpfsel0().set_bits(|w| {w.fsel0().input()}) };

        Pin0 { _mode: PhantomData }
    }

    pub fn into_output(self) -> Pin0<Output> {
        unsafe { (*GPIO::PTR).gpfsel0().set_bits(|w| {w.fsel0().output()})}

        P0i { _mode: PhantomData }
    }

    pub fn into_output_low(self) -> Pin0<Output> {
        unsafe { (*GPIO::PTR).gpfsel0().set_bits(|w| {w.fsel0().output()})}

        P0i { _mode: PhantomData }
    }

    pub fn into_output_high(self) -> Pin0<Output> {
        unsafe { (*GPIO::PTR).gpfsel0().set_bits(|w| {w.fsel0().output()})}

        P0i { _mode: PhantomData }
    }
}
\end{lstlisting}

Note the actual register write operations, the raw address,
the bit offset as well as the written value have all been transformed into constants and methods when generating the PAC.
Because these are writes to arbitrary memory adresses, they are unsafe.
But, in contrast to the circle implementation, we are not using unsafe here because we don't care about memory safety,
but rather for its intended purpose to tell the compiler that we checked we are upholding all the safety guarantees.
In this case the register writes are safe for two reasons.
For one, we know that there will never be unrelated data at this address, as it is hardwired to the MMIO.
Second, set\_bits() is atomic so we don't get race conditions from multiple pins using the same fsel register switching their modes.
This leaves implementing the embedded-hal traits for the pins. For a normal gpio pin these are InputPin with is\_high() and is\_low() as well as OutputPin with set\_high() and set\_low().

\begin{lstlisting}[language=Rust,style=colouredRust]
impl<MODE> hal::digital::InputPin for Pin0<Input<MODE>> {
    fn is_high(&mut self) -> Result<bool, Self::Error>{
        Ok(unsafe{ (*GPIO::PTR).gplev0().read().lev0().bit_is_set() })
    }

    fn is_low(&mut self) -> Result<bool, Self::Error> {
        Ok(unsafe{ (*GPIO::PTR).gplev0().read().lev0().bit_is_clear() })
    }
}

impl<MODE> hal::digital::ErrorType for Pin0<MODE> {
    type Error = Infallible;
}

impl hal::digital::OutputPin for Pin0<Output> {
    fn set_low(&mut self) -> Result<(), Self::Error> {
        Ok(unsafe{ (*GPIO::PTR).gpset0().write_with_zero(|w| {w.set0().set_bit()}) })
    }

    fn set_high(&mut self) -> Result<(), Self::Error> {
        Ok(unsafe{ (*GPIO::PTR).gpclr0().write_with_zero(|w| {w.clr0().clear_bit_by_one()}) })
    }
}
\end{lstlisting}

